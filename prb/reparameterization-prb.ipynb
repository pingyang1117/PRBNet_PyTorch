{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7cbe5ee",
   "metadata": {},
   "source": [
    "# Reparameterization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4330a635",
   "metadata": {},
   "source": [
    "## PRB reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72366828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "cfg_path = r\"cfg/deploy/PRB-FPN.yaml\"\n",
    "ckpt_path = r\"prb-fpn_training.pt\"  # checkpoints of prb with IDetect layer\n",
    "save_path = r\"prb-fpn.pt\"  # output file path\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "model = Model(cfg_path, ch=3, nc=80).to(device)\n",
    "\n",
    "with open(cfg_path) as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'])\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "# reparametrized YOLOR\n",
    "for i in range((model.nc+5)*anchors):  \n",
    "    model.state_dict()['model.108.m.0.weight'].data[i, :, :, :] *= state_dict['model.108.im.0.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.108.m.1.weight'].data[i, :, :, :] *= state_dict['model.108.im.1.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.108.m.2.weight'].data[i, :, :, :] *= state_dict['model.108.im.2.implicit'].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.108.m.0.bias'].data += state_dict['model.108.m.0.weight'].mul(state_dict['model.108.ia.0.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.108.m.1.bias'].data += state_dict['model.108.m.1.weight'].mul(state_dict['model.108.ia.1.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.108.m.2.bias'].data += state_dict['model.108.m.2.weight'].mul(state_dict['model.108.ia.2.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.108.m.0.bias'].data *= state_dict['model.108.im.0.implicit'].data.squeeze()\n",
    "model.state_dict()['model.108.m.1.bias'].data *= state_dict['model.108.im.1.implicit'].data.squeeze()\n",
    "model.state_dict()['model.108.m.2.bias'].data *= state_dict['model.108.im.2.implicit'].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "torch.save(ckpt, save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fff0da46",
   "metadata": {},
   "source": [
    "## PRB-FPN6-3PY reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load('PRB-FPN6-3PY-training.pt', map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "model = Model('cfg/deploy/PRB-FPN6-3PY.yaml', ch=3, nc=80).to(device)\n",
    "\n",
    "with open('cfg/deploy/PRB-FPN6-3PY.yaml') as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'][0]) // 2\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "\n",
    "idx = 190\n",
    "idx2 = 194\n",
    "\n",
    "# copy weights of lead head\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data -= model.state_dict()['model.{}.m.0.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data -= model.state_dict()['model.{}.m.1.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data -= model.state_dict()['model.{}.m.2.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data -= model.state_dict()['model.{}.m.3.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data -= model.state_dict()['model.{}.m.0.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data -= model.state_dict()['model.{}.m.1.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data -= model.state_dict()['model.{}.m.2.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data -= model.state_dict()['model.{}.m.3.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.bias'.format(idx2)].data\n",
    "\n",
    "# reparametrized YOLOR\n",
    "for i in range((model.nc+5)*anchors):\n",
    "    model.state_dict()['model.{}.m.0.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.0.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.1.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.1.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.2.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.2.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.3.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.3.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].mul(state_dict['model.{}.ia.0.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].mul(state_dict['model.{}.ia.1.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].mul(state_dict['model.{}.ia.2.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].mul(state_dict['model.{}.ia.3.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data *= state_dict['model.{}.im.0.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data *= state_dict['model.{}.im.1.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data *= state_dict['model.{}.im.2.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data *= state_dict['model.{}.im.3.implicit'.format(idx2)].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "torch.save(ckpt, 'PRB-FPN6-3PY.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0867ae1e",
   "metadata": {},
   "source": [
    "## PRB-FPN6-MSP reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24dfe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load('PRB-FPN6-MSP-training.pt', map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "model = Model('cfg/deploy/PRB-FPN6-MSP.yaml', ch=3, nc=80).to(device)\n",
    "\n",
    "with open('cfg/deploy/PRB-FPN6-MSP.yaml') as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'][0]) // 2\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "\n",
    "idx = 43\n",
    "idx2 = 47\n",
    "\n",
    "# copy weights of lead head\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data -= model.state_dict()['model.{}.m.0.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data -= model.state_dict()['model.{}.m.1.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data -= model.state_dict()['model.{}.m.2.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data -= model.state_dict()['model.{}.m.3.weight'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.weight'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.weight'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.weight'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.weight'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data -= model.state_dict()['model.{}.m.0.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data -= model.state_dict()['model.{}.m.1.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data -= model.state_dict()['model.{}.m.2.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data -= model.state_dict()['model.{}.m.3.bias'.format(idx)].data\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.bias'.format(idx2)].data\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.bias'.format(idx2)].data\n",
    "\n",
    "# reparametrized YOLOR\n",
    "for i in range((model.nc+5)*anchors):\n",
    "    model.state_dict()['model.{}.m.0.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.0.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.1.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.1.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.2.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.2.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.{}.m.3.weight'.format(idx)].data[i, :, :, :] *= state_dict['model.{}.im.3.implicit'.format(idx2)].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data += state_dict['model.{}.m.0.weight'.format(idx2)].mul(state_dict['model.{}.ia.0.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data += state_dict['model.{}.m.1.weight'.format(idx2)].mul(state_dict['model.{}.ia.1.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data += state_dict['model.{}.m.2.weight'.format(idx2)].mul(state_dict['model.{}.ia.2.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data += state_dict['model.{}.m.3.weight'.format(idx2)].mul(state_dict['model.{}.ia.3.implicit'.format(idx2)]).sum(1).squeeze()\n",
    "model.state_dict()['model.{}.m.0.bias'.format(idx)].data *= state_dict['model.{}.im.0.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.1.bias'.format(idx)].data *= state_dict['model.{}.im.1.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.2.bias'.format(idx)].data *= state_dict['model.{}.im.2.implicit'.format(idx2)].data.squeeze()\n",
    "model.state_dict()['model.{}.m.3.bias'.format(idx)].data *= state_dict['model.{}.im.3.implicit'.format(idx2)].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "torch.save(ckpt, 'PRB-FPN6-MSP.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
